<!doctype html><html lang=en><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content="map[name:Jose Coelho]"><meta name=description content="Ramblings about software engineering"><meta name=keywords content="go,golang,kubernetes,ansible,chef,kafka,docker,containers"><link rel=canonical href=https://www.jacoelho.com/blog/2016/11/kafka-accelerating/><title>Kafka — Accelerating! :: Posts</title><link rel=stylesheet href=https://www.jacoelho.com/css/main.min.119ac2c18046a4ef9e7705b9cd71e1fc8cbe5a5139a1234cfdae109d1baedb3c.css integrity="sha256-EZrCwYBGpO+edwW5zXHh/Iy+WlE5oSNM/a4QnRuu2zw=" crossorigin=anonymous><meta itemprop=name content="Kafka — Accelerating!"><meta itemprop=description content="Quick tips and insights on how to make Apache Kafka
work faster!
Hardware CPU doesn’t matter that much. Memory helps a lot (a lot) in performance. SSDs are not required, since most operations are sequential read and writes. If possible run in bare
metal. Linux Configure to maximize memory
usage (tweak until you feel comfortable): vm.dirty_background_ratio = 5 vm.dirty_ratio = 80 vm.swappiness = 1 Assuming you are using ext4, don’t waste space with reserved blocks: tune2fs -m 0 -i 0 -c -1 /dev/device Mount with noatime: /dev/device /mountpoint ext4 defaults,noatime Keep an eye on the number of free inodes: tune2fs -l /dev/device | grep -i inode Increase limits, for example, using systemd: $ cat /etc/systemd/system/kafka.service.d/limits.conf [Service] LimitNOFILE=10000 Tweak your network settings, for example: net.core.somaxconn = 1024 net.core.rmem_max = 67108864 net.core.wmem_max = 67108864 net.ipv4.tcp_rmem = 4096 87380 33554432 net.ipv4.tcp_wmem = 4096 65536 33554432 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_syncookies = 1 Kafka log.dirs accepts a comma separated list of disks and will distribute
partitions across them, however: Doesn’t rebalance, some disks could be full and others empty. Doesn’t tolerate any disk failure, more info in
KIP-18. Raid 10 is probably the best middle ground between performance and
reliability. *num.io.threads, *number of I/O threads that the server uses for executing
requests. You should have at least as many threads as you have disks. num.network.threads, number of network threads that the server uses for
handling network requests. Increase based on number of producers/consumers and
replication factor. Use Java 1.8 and G1 Garbage
collector: -XX:MetaspaceSize=96m -XX:+UseG1GC # use G1 -XX:MaxGCPauseMillis=20 # gc deadline -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 KAFKA_HEAP_OPTS, 5–8Gb heap should be enough for most deployments, file system
cache is way more important. Linkedin runs 5Gb heap in 32Gb RAM
servers. pcstat can help understand how well the
system is caching: ./pcstat /kafka/data/* Any comments or suggestions are welcome!"><meta itemprop=datePublished content="2016-11-22T10:24:46+00:00"><meta itemprop=dateModified content="2016-11-22T10:24:46+00:00"><meta itemprop=wordCount content="303"><meta itemprop=keywords content="Kafka"><meta property="og:url" content="https://www.jacoelho.com/blog/2016/11/kafka-accelerating/"><meta property="og:site_name" content="Posts"><meta property="og:title" content="Kafka — Accelerating!"><meta property="og:description" content="Quick tips and insights on how to make Apache Kafka
work faster!
Hardware CPU doesn’t matter that much. Memory helps a lot (a lot) in performance. SSDs are not required, since most operations are sequential read and writes. If possible run in bare
metal. Linux Configure to maximize memory
usage (tweak until you feel comfortable): vm.dirty_background_ratio = 5 vm.dirty_ratio = 80 vm.swappiness = 1 Assuming you are using ext4, don’t waste space with reserved blocks: tune2fs -m 0 -i 0 -c -1 /dev/device Mount with noatime: /dev/device /mountpoint ext4 defaults,noatime Keep an eye on the number of free inodes: tune2fs -l /dev/device | grep -i inode Increase limits, for example, using systemd: $ cat /etc/systemd/system/kafka.service.d/limits.conf [Service] LimitNOFILE=10000 Tweak your network settings, for example: net.core.somaxconn = 1024 net.core.rmem_max = 67108864 net.core.wmem_max = 67108864 net.ipv4.tcp_rmem = 4096 87380 33554432 net.ipv4.tcp_wmem = 4096 65536 33554432 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_syncookies = 1 Kafka log.dirs accepts a comma separated list of disks and will distribute
partitions across them, however: Doesn’t rebalance, some disks could be full and others empty. Doesn’t tolerate any disk failure, more info in
KIP-18. Raid 10 is probably the best middle ground between performance and
reliability. *num.io.threads, *number of I/O threads that the server uses for executing
requests. You should have at least as many threads as you have disks. num.network.threads, number of network threads that the server uses for
handling network requests. Increase based on number of producers/consumers and
replication factor. Use Java 1.8 and G1 Garbage
collector: -XX:MetaspaceSize=96m -XX:+UseG1GC # use G1 -XX:MaxGCPauseMillis=20 # gc deadline -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 KAFKA_HEAP_OPTS, 5–8Gb heap should be enough for most deployments, file system
cache is way more important. Linkedin runs 5Gb heap in 32Gb RAM
servers. pcstat can help understand how well the
system is caching: ./pcstat /kafka/data/* Any comments or suggestions are welcome!"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2016-11-22T10:24:46+00:00"><meta property="article:modified_time" content="2016-11-22T10:24:46+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Kafka — Accelerating!"><meta name=twitter:description content="Quick tips and insights on how to make Apache Kafka
work faster!
Hardware CPU doesn’t matter that much. Memory helps a lot (a lot) in performance. SSDs are not required, since most operations are sequential read and writes. If possible run in bare
metal. Linux Configure to maximize memory
usage (tweak until you feel comfortable): vm.dirty_background_ratio = 5 vm.dirty_ratio = 80 vm.swappiness = 1 Assuming you are using ext4, don’t waste space with reserved blocks: tune2fs -m 0 -i 0 -c -1 /dev/device Mount with noatime: /dev/device /mountpoint ext4 defaults,noatime Keep an eye on the number of free inodes: tune2fs -l /dev/device | grep -i inode Increase limits, for example, using systemd: $ cat /etc/systemd/system/kafka.service.d/limits.conf [Service] LimitNOFILE=10000 Tweak your network settings, for example: net.core.somaxconn = 1024 net.core.rmem_max = 67108864 net.core.wmem_max = 67108864 net.ipv4.tcp_rmem = 4096 87380 33554432 net.ipv4.tcp_wmem = 4096 65536 33554432 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_syncookies = 1 Kafka log.dirs accepts a comma separated list of disks and will distribute
partitions across them, however: Doesn’t rebalance, some disks could be full and others empty. Doesn’t tolerate any disk failure, more info in
KIP-18. Raid 10 is probably the best middle ground between performance and
reliability. *num.io.threads, *number of I/O threads that the server uses for executing
requests. You should have at least as many threads as you have disks. num.network.threads, number of network threads that the server uses for
handling network requests. Increase based on number of producers/consumers and
replication factor. Use Java 1.8 and G1 Garbage
collector: -XX:MetaspaceSize=96m -XX:+UseG1GC # use G1 -XX:MaxGCPauseMillis=20 # gc deadline -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 KAFKA_HEAP_OPTS, 5–8Gb heap should be enough for most deployments, file system
cache is way more important. Linkedin runs 5Gb heap in 32Gb RAM
servers. pcstat can help understand how well the
system is caching: ./pcstat /kafka/data/* Any comments or suggestions are welcome!"><meta property="article:published_time" content="2016-11-22 10:24:46 +0000 UTC"><meta property="article:section" content="kafka"></head><body><header class=header><div class=container><div class=header-inner><a href=https://www.jacoelho.com/ class=logo>Jose Coelho</a><nav class=nav><ul class=menu><li class=menu-item><a href=https://www.jacoelho.com/about/>About</a></li></ul><button class=menu-trigger aria-label="Toggle menu" aria-expanded=false>
<svg width="24" height="24"><use href="https://www.jacoelho.com/icons.svg#menu"/></svg>
</button>
<button class=theme-toggle aria-label="Toggle theme">
<svg class="theme-icon-light" width="20" height="20"><use href="https://www.jacoelho.com/icons.svg#sun"/></svg>
<svg class="theme-icon-dark" width="20" height="20"><use href="https://www.jacoelho.com/icons.svg#moon"/></svg>
</button>
<a href=https://www.jacoelho.com/index.xml class=rss-link target=_blank rel=noopener aria-label=RSS><svg width="20" height="20"><use href="https://www.jacoelho.com/icons.svg#rss"/></svg></a></nav></div></div></header><div class=container><div class=content><main class=post><article><header class=post-header><h1 class=post-title>Kafka — Accelerating!</h1><div class=post-meta><span class=post-meta-item><time datetime=2016-11-22>November 22, 2016</time></span></div></header><div class=post-content><p>Quick tips and insights on how to make <a href=https://kafka.apache.org/>Apache Kafka</a><br>work faster!</p><h3 id=hardware>Hardware</h3><ul><li>CPU doesn&rsquo;t matter that much.</li><li>Memory helps a lot (a lot) in performance.</li><li>SSDs are not required, since most operations are sequential read and writes.</li><li>If possible run in <a href=https://www.ibm.com/blogs/cloud-computing/2014/07/bare-metal-vs-virtual-servers-choice-right/>bare<br>metal</a>.</li></ul><h3 id=linux>Linux</h3><ul><li>Configure to <a href=http://www.makelinux.net/books/lkd2/ch15lev1sec4>maximize memory<br>usage</a> (tweak until you feel comfortable):</li></ul><pre tabindex=0><code>vm.dirty_background_ratio = 5
vm.dirty_ratio = 80
vm.swappiness = 1
</code></pre><ul><li>Assuming you are using <em>ext4</em>, don’t waste space with reserved blocks:</li></ul><pre tabindex=0><code>tune2fs -m 0 -i 0 -c -1 /dev/device
</code></pre><ul><li>Mount with <em>noatime</em>:</li></ul><pre tabindex=0><code>/dev/device       /mountpoint       ext4    defaults,noatime
</code></pre><ul><li>Keep an eye on the number of free <em>inodes</em>:</li></ul><pre tabindex=0><code>tune2fs -l /dev/device | grep -i inode
</code></pre><ul><li>Increase limits, for example, using <em>systemd</em>:</li></ul><pre tabindex=0><code>$ cat /etc/systemd/system/kafka.service.d/limits.conf
[Service]
LimitNOFILE=10000
</code></pre><ul><li>Tweak your network settings, for example:</li></ul><pre tabindex=0><code>net.core.somaxconn = 1024
net.core.rmem_max = 67108864
net.core.wmem_max = 67108864
net.ipv4.tcp_rmem = 4096 87380 33554432
net.ipv4.tcp_wmem = 4096 65536 33554432
net.ipv4.tcp_max_syn_backlog = 4096
net.ipv4.tcp_syncookies = 1
</code></pre><h3 id=kafka>Kafka</h3><ul><li><em>log.dirs</em> accepts a comma separated list of disks and will distribute<br>partitions across them, however:</li></ul><ol><li>Doesn’t rebalance, some disks could be full and others empty.</li><li>Doesn’t tolerate any disk failure, more info in<br><a href=https://cwiki.apache.org/confluence/display/KAFKA/KIP-18+-+JBOD+Support>KIP-18</a>.</li><li><em>Raid 10</em> is probably the best middle ground between performance and<br>reliability.</li></ol><ul><li>*num.io.threads, *number of I/O threads that the server uses for executing<br>requests. You should have at least as many threads as you have disks.</li><li><em>num.network.threads</em>, number of network threads that the server uses for<br>handling network requests. Increase based on number of producers/consumers and<br>replication factor.</li><li>Use Java 1.8 and <a href=http://www.oracle.com/technetwork/articles/java/g1gc-1984535.html>G1 Garbage<br>collector</a>:</li></ul><pre tabindex=0><code>-XX:MetaspaceSize=96m
-XX:+UseG1GC            # use G1
-XX:MaxGCPauseMillis=20 # gc deadline
-XX:InitiatingHeapOccupancyPercent=35
-XX:G1HeapRegionSize=16M
-XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80
</code></pre><ul><li><em>KAFKA_HEAP_OPTS</em>, 5–8Gb heap should be enough for most deployments, file system<br>cache is way more important. <em>Linkedin</em> runs <a href=http://docs.confluent.io/1.0/kafka/deployment.html>5Gb heap in 32Gb RAM<br>servers</a>.</li><li><a href=https://github.com/tobert/pcstat>pcstat</a> can help understand how well the<br>system is caching:</li></ul><pre tabindex=0><code>./pcstat /kafka/data/*
</code></pre><hr><p>Any comments or suggestions are welcome!</p></div><div class=post-categories><a href=https://www.jacoelho.com/categories/kafka class=category>kafka</a></div></article></main></div></div><footer class=footer><div class=container><div class=footer-content><span>&copy; 2025 Jose Coelho</span></div></div></footer><script src=https://www.jacoelho.com/js/bundle.min.2868f841c78e77d7b473d034a52bb46f21b12eef84caba5767ed9a65576ecb3c.js integrity="sha256-KGj4QceOd9e0c9A0pSu0byGxLu+EyrpXZ+2aZVduyzw=" crossorigin=anonymous></script></body></html>